{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author\n",
    "Junseong Ahn\n",
    "### Laboratory \n",
    " Perception, Control, Cognition Lab : Brigham Young University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.morphology import disk\n",
    "from skimage import data\n",
    "from skimage.filters import rank\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the path for this demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video path\n",
    "video_path = 'IMG_4296.MOV'\n",
    "#basename for images from video  \n",
    "img_name = 'image'\n",
    "#path of saved images  \n",
    "img_path = 'images_resized'\n",
    "#frame rate for saving video \n",
    "frameRate = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_img_path = os.path.join(img_path, img_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background-Subtraction with moving scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background Subtraction is usually used for stationary scene, however, with an assumption, the background is plain, we can use the technique for a moving scene video. This is my work of background subtraction algrotihm for a moving scene. Note that this jupter notebook is analyzing just one of videos (IMG_4296.MOV) since we can use normal background suppression techniques for the second video(orcalab-rubbing-beach-underwater.mp4).\n",
    "\n",
    "Also, Note that this notebook is the half of all the algorithm procedures (what was in the presentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video2Image(video_path, save_path, frameRate):\n",
    "    \"\"\"\n",
    "    change video to images and save to save_path with frameRate.\n",
    "    Param:\n",
    "        video_path (str) : path of video\n",
    "        save_path : save path of image\n",
    "        frameRate : the frame of video to save\n",
    "    \"\"\"\n",
    "    vidcap = cv2.VideoCapture(name_video)\n",
    "    def getFrame(sec):\n",
    "        vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "        hasFrames,image = vidcap.read()\n",
    "        if hasFrames:\n",
    "            image = img = cv2.resize(image, (int(image.shape[1]), int(image.shape[0])))\n",
    "            cv2.imwrite(save_path+str(count)+\".jpg\", image)     # save frame as JPG file\n",
    "        return hasFrames\n",
    "    \n",
    "    sec =0\n",
    "    count=1\n",
    "    success = getFrame(sec)\n",
    "    start = time.time()\n",
    "    while success:\n",
    "        count = count + 1\n",
    "        sec = sec + frameRate\n",
    "        sec = round(sec, 2)\n",
    "        success = getFrame(sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImages(img_name, img_path, n_img):\n",
    "    \"\"\"\n",
    "    Get color images(.jpg) from img_path. \n",
    "    Note that it is the order of the images should be next to img_name.(e.g tree13)\n",
    "    \"\"\"\n",
    "    image_names = [img_name+str(i)+\".jpg\" for i in range(n_img)]\n",
    "    imgs = [cv2.imread(os.path.join(img_path,image_names[i]), cv2.IMREAD_GRAYSCALE) for i in range(1,len(image_names))]\n",
    "    imgs_color = [cv2.imread(os.path.join(img_path,image_names[i]), cv2.COLOR_BGR2RGB) for i in range(1,len(image_names))]\n",
    "\n",
    "    return imgs, imgs_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, imgs_color = getImages(img_name, img_path, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normal background suppression using open-cv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "fgbgAdaptiveGaussain = cv2.createBackgroundSubtractorMOG2()\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "fgbgBayesianSegmentation = cv2.bgsegm.createBackgroundSubtractorGMG()\n",
    "\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    fgmask = fgbg.apply(imgs[i])\n",
    "    fgbgAdaptiveGaussainmask = fgbgAdaptiveGaussain.apply(imgs[i])\n",
    "    fgbgBayesianSegmentationmask = fgbgBayesianSegmentation.apply(imgs[i])\n",
    "    fgbgBayesianSegmentationmask = cv2.morphologyEx(fgbgBayesianSegmentationmask,cv2.MORPH_OPEN,kernel)\n",
    "\n",
    "    cv2.namedWindow('Background Subtraction Bayesian Segmentation',0)\n",
    "    cv2.namedWindow('Background Subtraction',0)\n",
    "    cv2.namedWindow('Background Subtraction Adaptive Gaussian',0)\n",
    "    cv2.namedWindow('Original',0)\n",
    "\n",
    "    cv2.resizeWindow('Original', 450,450)\n",
    "    cv2.imshow('Background Subtraction Bayesian Segmentation',fgbgBayesianSegmentationmask)\n",
    "    cv2.imshow('Background Subtraction',fgmask)\n",
    "    cv2.imshow('Background Subtraction Adaptive Gaussian',fgbgAdaptiveGaussainmask)\n",
    "    cv2.imshow('Original',imgs[i])\n",
    "\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "\n",
    "    if k==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the result\n",
    "\n",
    "As you can see, because the camera was moving, the background aglorithm can't differeniate the background(the mountain) and the ship; therefore, I propose background suppression using 3D morpholocal Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D morhpholocal Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackgroundSuppression():\n",
    "    \"\"\"\n",
    "    Dynaimcally calculate gradient flows to simulate real video situation.\n",
    "    \"\"\"\n",
    "    def __init__(self, imgs, imgs_color, k, kernel_size):\n",
    "        if len(imgs) < k:\n",
    "            raise ValueError(\"you need at least %d number of images\"%d)\n",
    "        self.img_size = imgs[0].shape\n",
    "        self.imgs = [cv2.GaussianBlur(imgs[i],(5,5),cv2.BORDER_DEFAULT) for i in range(len(imgs))]\n",
    "        self.imgs_color = imgs_color\n",
    "        self.k = k\n",
    "        self.kernel = np.ones((kernel_size,kernel_size),np.uint8)\n",
    "        \n",
    "        self.dilations = np.array([cv2.dilate(self.imgs[i], self.kernel,iterations=1) for i in range(k-1)])\n",
    "        self.erosions = np.array([cv2.erode(self.imgs[i], self.kernel,iterations=1) for i in range(k-1)])\n",
    "        \n",
    "        self.gradients = self.dilations - self.erosions\n",
    "        self.gradients3d = [self.calculate3dGradientVectorize(i, 0, stability=False, init=True) for i in range(0,k-1)]            \n",
    "            \n",
    "    def update(self, img):\n",
    "        blur_img = cv2.GaussianBlur(img,(5,5),cv2.BORDER_DEFAULT)\n",
    "        dilation, erosion = np.expand_dims(cv2.dilate(blur_img, self.kernel,iterations=1), axis=0),\\\n",
    "                            np.expand_dims(cv2.erode(blur_img, self.kernel,iterations=1), axis=0)\n",
    "        gradient = dilation - erosion\n",
    "        self.dilations = np.concatenate((self.dilations, dilation),axis=0)\n",
    "        self.erosions = np.concatenate((self.erosions,erosion),axis=0)\n",
    "        self.gradients = np.concatenate((self.gradients,gradient),axis=0)\n",
    "\n",
    "    \n",
    "    def calculate3dGradientVectorize(self, inx, weights=1, stability=True, init=False):\n",
    "        \"\"\"\n",
    "        Calculate gradient in the time interval t. if weights is not zero, we don't have any speical attention to current scene\n",
    "        it is for stability option of background.\n",
    "        \"\"\"\n",
    "        if init:\n",
    "            dilation3d = np.max(self.dilations[0:inx+1], axis=0)\n",
    "            erosion3d = np.min(self.erosions[0:inx+1], axis=0)\n",
    "            #get gradient standard deviation if it is first frame, diff is 1\n",
    "            if inx == 0:\n",
    "                diff = np.ones_like(self.gradients[0])\n",
    "            else:\n",
    "                diff = np.std(self.gradients[0:inx+1], axis=0)\n",
    "        else:\n",
    "            dilation3d = np.max(self.dilations[-self.k:], axis=0)\n",
    "            erosion3d = np.min(self.erosions[-self.k:], axis=0)\n",
    "            #get gradient standard deviation\n",
    "            diff = np.std(self.gradients[-self.k:].copy(), axis=0)\n",
    "\n",
    "        \n",
    "        if stability:\n",
    "            prev_gradients = self.gradients3d[-(k+1):]\n",
    "            current_grad3d = dilation3d - erosion3d\n",
    "            #if weights are not zero, we have more attention/less attention to current grad\n",
    "            if weight != 0:\n",
    "                current_grad3d += weight*current_grad3d\n",
    "            #get mean of gradient in k time interval\n",
    "            grad3d = np.mean(prev_gradients.extend(current_grad3d), axis=0)\n",
    "        else:\n",
    "            grad3d = dilation3d - erosion3d\n",
    "        \n",
    "\n",
    "\n",
    "        #for normalize std, we divide by max of diff\n",
    "        grad3d = grad3d * diff / np.max(diff)\n",
    "        return grad3d\n",
    "    \n",
    "    def showImages(self, option):\n",
    "        \"\"\"\n",
    "        params\n",
    "        options (int):\n",
    "            1. 3d grad\n",
    "            2. image flow with 3dgrad\n",
    "        \"\"\"\n",
    "\n",
    "        prvs = self.gradients3d[0]\n",
    "        if option == 1:\n",
    "            hsv = np.zeros_like(imgs[0])\n",
    "        else:\n",
    "            hsv = np.zeros_like(imgs_color[0])\n",
    "        hsv[...,1] = 255\n",
    "\n",
    "        alpha = 6\n",
    "        \n",
    "        print(len(self.imgs))\n",
    "        for i in range(self.k-1, len(self.imgs)):            \n",
    "            self.update(imgs[i])\n",
    "            self.gradients3d.append(self.calculate3dGradientVectorize(i, stability=False))\n",
    "            \n",
    "            if option == 1:\n",
    "                #the reason we thresh holding value with the gradient mean times alpha is \n",
    "                # there are a lot more background and the mean is skewed; there should be non-hard coding way to find using std\n",
    "                frame = (self.gradients3d[i]>alpha*self.gradients3d[i].mean()).astype(np.uint8)*255\n",
    "                frame_name = \"3d grad\"\n",
    "            elif option == 2:\n",
    "                #calculate optimal flow between two gradients with Lucas–Kanade method\n",
    "                # https://en.wikipedia.org/wiki/Lucas%E2%80%93Kanade_method\n",
    "\n",
    "                flow = cv2.calcOpticalFlowFarneback(self.gradients3d[i-1],self.gradients3d[i], None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "                mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "                hsv[...,0] = ang*180/np.pi/2\n",
    "                hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "                rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "                frame = imgs_color[i]+rgb\n",
    "#                 print(flow.shape)\n",
    "#                 asdf\n",
    "                frame_name = \"Optical flow: directional gradient of 3d Morphological gradient\"\n",
    "            cv2.imshow(frame_name,frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Release everything if job is finished\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "backgroundsuppression = BackgroundSuppression(imgs, imgs_color, 3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n"
     ]
    }
   ],
   "source": [
    "backgroundsuppression.showImages(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: What is alpha?\n",
    "\n",
    "As you can see there is hyperparamter alpha when we are threshholding low gradient. The reason that I have mean*alpha is that there are signicantly more background than the foreground. Therefore, the mean is skewed. I think there is a way to find this parameter rather than hard coding it (e.g. check skewness of gradients) \n",
    "\n",
    "In addiiton, in the presentation, Dr. Mukherjee suggests that we can use some transformation to remove the gradient for background; however, I need to think about it more.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: why does my background supression method is getting slower after few seconds?\n",
    "\n",
    "When we run %prun backgroundsuppression.showImages(1), to process 249 images, it takes 28 second without any optimization (0.1second per frame). However, if I profile this, I can make it much faster.\n",
    "\n",
    "\n",
    "For example, actually I don't need to use np concatenate (by saving the only interval arrays), it takes most of time (20 seconds, for more information please, look at this link  <a href=\"https://drive.google.com/open?id=12147WdU7pQY-jTxgpzwpeaRVkoQ-JxHE\">Time Per Line</a>), which means we can change 28 second to almost 8 second(0.03 second per frame).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backgroundsuppression.showImages(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /io/opencv/modules/core/src/array.cpp:2492: error: (-206:Bad flag (parameter or structure field)) Unrecognized or unsupported array type in function 'cvGetMat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e447f76cd771>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbackgroundsuppression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-b39639a4b2e2>\u001b[0m in \u001b[0;36mshowImages\u001b[0;34m(self, option)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs_color\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mframe_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optical flow: directional gradient of 3d Morphological gradient\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /io/opencv/modules/core/src/array.cpp:2492: error: (-206:Bad flag (parameter or structure field)) Unrecognized or unsupported array type in function 'cvGetMat'\n"
     ]
    }
   ],
   "source": [
    "backgroundsuppression.showImages(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do I interperate backgroundsuppression.showImages(2)?\n",
    "\n",
    "Meaning of flow Markers\n",
    "<ul>\n",
    "    <li>The intensity of color: the velocity of pixel</li>\n",
    "    <li>The kind of color: the direction of pixel</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "<ul>\n",
    "        <li>Gandhi, T. L. (1999). Image sequence analysis for object detection and segmentation.</li>\n",
    "    <li>Pardàs, M., & Salembier, P. (1994). 3D morphological segmentation and motion estimation for image sequences. Signal processing, 38(1), 31-43.</li>\n",
    "    <li>Stauffer, C., & Grimson, W. E. L. (2000). Learning patterns of activity using real-time tracking. IEEE Transactions on pattern analysis and machine intelligence, 22(8), 747-757.</li>\n",
    "    <li>Mukherjee, D., Wu, Q. J., & Nguyen, T. M. (2013). Gaussian mixture model with advanced distance measure based on support weights and histogram of gradients for background suppression. IEEE Transactions on Industrial Informatics, 10(2), 1086-1096.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
